{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Языковые модели\n",
    "\n",
    "Какое слово в последовательности вероятнее: \n",
    "\n",
    "Поезд прибыл на\n",
    "* вокзал\n",
    "* север\n",
    "\n",
    "Какая последовательность вероятнее:\n",
    "* Вокзал прибыл поезд на\n",
    "* Поезд прибыл на вокзал\n",
    "\n",
    "Языковая модель [language model, LM]  позволяет оценить вероятность следующего слова в последовательности  $P(w_n | w_1, \\ldots, w_{n-1})$ и оценить вероятность всей последовательности слов $P(w_1, \\ldots, w_n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Приложения:\n",
    "* Задачи, в которых нужно обработать сложный и зашумленный вход: распознавание речи, распознавание сканированных и рукописных текстов;\n",
    "* Исправление опечаток\n",
    "* Машинный перевод\n",
    "* Подсказка при наборе "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Виды моделей:\n",
    "* Счетные модели\n",
    "    * цепи Маркова\n",
    "* Нейронные модели, обычно реккурентные нейронные сети с LSTM/GRU\n",
    "* seq2seq архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Модель $n$-грам\n",
    "\n",
    "Пусть $w_{1:n}=w_1,\\ldots,w_m$ – последовательность слов.\n",
    "\n",
    "Цепное правило:\n",
    "$ P(w_{1:m}) = P(w_1) P(w_2 | w_1) P(w_3 | w_{1:2}) \\ldots P(w_m | w_{1:m-1}) = \\prod_{k=1}^{m} P(w_k | w_{1:k-1}) $\n",
    "\n",
    "Но оценить $P(w_k | w_{1:k-1})$ не легче! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Переходим к $n$-грамам: $P(w_{i+1} | w_{1:i}) \\approx P(w_{i+1} | w_{i-n:i})  $ , то есть, учитываем $n-1$ предыдущее слово. \n",
    "\n",
    "Модель\n",
    "* униграм: $P(w_k)$\n",
    "* биграм: $P(w_k | w_{k-1})$\n",
    "* триграм: $P(w_k | w_{k-1} w_{k-2})$\n",
    "\n",
    "\n",
    "Т.е. используем Марковские допущения о длине запоминаемой цепочки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Вероятность следующего слова в последовательности: $ P(w_{i+1} | w_{1:i}) \\approx P(w_{i-n:i}) $\n",
    "* Вероятность всей последовательности слов: $P(w_{1:n}) = \\prod_{k=1}^l P(w_k | w_{k-n+1: k-1}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Качество модели  $n$-грам\n",
    "\n",
    "Перплексия: насколько хорошо модель предсказывает выборку. Чем ниже значение перплексии, тем лучше.\n",
    "\n",
    "$PP(\\texttt{LM}) = 2 ^ {-\\frac{1}{m} \\log_2 \\texttt{LM} (w_i | w_{1:i-1})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Счетные языковые модели\n",
    "\n",
    "### ММП оценки вероятностей\n",
    "$ P_{MLE}(w_k | w_{k-n+1:k-1}) = \\frac{\\texttt{count}(w_{k-n+1:k-1} w_k )}{\\texttt{count}(w_{k-n+1:k-1} )} $\n",
    "\n",
    "В модели биграм:\n",
    "\n",
    "$ P_{MLE}(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k )}{\\texttt{count}(w_{k-1} )} $\n",
    "\n",
    "Возникает проблема нулевых вероятностей!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Аддитивное сглаживание Лапласа\n",
    "\n",
    "$ P(w_k | w_{k-1}) = \\frac{\\texttt{count}(w_{k-1} w_k ) + \\alpha}{\\texttt{count}(w_{k-1} ) + \\alpha |V|} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![AiB](img/aib.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BOS А и Б сидели на трубе EOS\n",
    "\n",
    "BOS А упало Б пропало EOS\n",
    "\n",
    "BOS что осталось на трубе EOS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$P($ и $| $ A $) = \\frac{1}{2}$\n",
    "\n",
    "$P($ Б $| $ и $) = \\frac{1}{1}$\n",
    "\n",
    "$P($ трубе $| $ на $) = \\frac{2}{2}$\n",
    "\n",
    "$P($ сидели $| $ Б $) = \\frac{1}{2}$\n",
    "\n",
    "$P($ на $| $ сидели $) = \\frac{1}{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Модели биграм в NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aachenosaurus', 'aardonyx', 'abdallahsaurus', 'abelisaurus', 'abrictosaurus', 'abrosaurus', 'abydosaurus', 'acanthopholis', 'achelousaurus', 'acheroraptor']\n"
     ]
    }
   ],
   "source": [
    "names = [name.strip().lower() for name in open('dinos.txt').readlines()]\n",
    "print(names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'g', 'f', 'j', 'k', 'w', 'z', 'q']\n"
     ]
    }
   ],
   "source": [
    "chars = [char  for name in names for char in name]\n",
    "freq = nltk.FreqDist(chars)\n",
    "\n",
    "print(list(freq.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 26,\n",
       "          'b': 32,\n",
       "          'c': 109,\n",
       "          'd': 41,\n",
       "          'e': 48,\n",
       "          'f': 7,\n",
       "          'g': 44,\n",
       "          'h': 21,\n",
       "          'i': 26,\n",
       "          'j': 8,\n",
       "          'k': 22,\n",
       "          'l': 146,\n",
       "          'm': 74,\n",
       "          'n': 354,\n",
       "          'o': 27,\n",
       "          'p': 96,\n",
       "          'q': 3,\n",
       "          'r': 131,\n",
       "          's': 187,\n",
       "          't': 213,\n",
       "          'u': 792,\n",
       "          'v': 34,\n",
       "          'w': 10,\n",
       "          'x': 12,\n",
       "          'y': 14,\n",
       "          'z': 10})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
    "cfreq['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(a a) = 0.0105\n",
      "p(a b) = 0.0129\n",
      "p(a u) = 0.3185\n"
     ]
    }
   ],
   "source": [
    "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
    "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
    "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
    "print('p(a u) = %1.4f' %cprob['a'].prob('u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.041317008359863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "log(cprob['a'].prob('a')) + log(cprob['a'].prob('b')) + log(cprob['a'].prob('c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(a) = 0.1354\n"
     ]
    }
   ],
   "source": [
    "l = sum([freq[char] for char in freq])\n",
    "def unigram_prob(char):\n",
    "    return freq[char] / l\n",
    "print('p(a) = %1.4f' %unigram_prob('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'a'),\n",
       " ('a', 'c'),\n",
       " ('c', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', 'n'),\n",
       " ('n', 'o'),\n",
       " ('o', 's'),\n",
       " ('s', 'a'),\n",
       " ('a', 'u'),\n",
       " ('u', 'r'),\n",
       " ('r', 'u'),\n",
       " ('u', 's')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bi for bi in nltk.bigrams('aachenosaurus')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задание 1\n",
    "\n",
    "1. Напишите функцию для оценки вероятности имени динозавра. \n",
    "2. Найдите наиболее вероятное имя динозавра из данного списка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cprob[\"a\"].generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задание 2\n",
    "\n",
    "Напишите функцию для генерации нового имени динозавра фиксированной длины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нейронные языковые модели\n",
    "\n",
    "* Вход: $n$-грамы $w_{1:k}$\n",
    "* $v(w_i)$ – эмбеддинг слова $w_i$, $v(w_i) \\in \\mathbb{R}^{d_{emb}}$, $d_{emb}$ – размерность эмбеддинга, $v(w) = E_{[w]}$\n",
    "* $x = [v(w_1), v(w_2), \\ldots , v(w_k)]$\n",
    "\n",
    "$\\widehat{y} = P(w_i | w_{1:k} ) = \\texttt{LM}(w_{1:k}) = \\texttt{softmax}(hW^2 +b^2)$\n",
    "\n",
    "$h = g(xW^1+b^1)$\n",
    "\n",
    "$w_i \\in V$, $E \\in \\mathbb{R}^{|V|\\times d_{emb}}, W^1 \\in \\mathbb{R}^{k \\cdot d_{emb} \\times d_{hid}}, b^1 \\in \\mathbb{R} ^ {d_{hid}}, W^2 \\in \\mathbb{R}^{d_{hid} \\times |V|}, b^2 \\in \\mathbb{R} ^ {|V|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![nnlm](img/nlm1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Семплирование в нейронных языковых моделях \n",
    "### (Генерация текстов с помощью нейронных языковых моделей)\n",
    "\n",
    "1. Задать начальную последовательность символов длины $k$ (/слов)\n",
    "2. Предсказать распределение вероятностей слов с условием на $k$ предыдущих слов\n",
    "3. 1. Выбрать слово с наибольшей вероятностью\n",
    "3. 2. Выбрать слово по предсказаному распределению\n",
    "4. Сдвинуть окно на одно слово и повторить \n",
    "\n",
    "#### Линейный поиск  (beam search)\n",
    "Всегда помним $h$ наиболее вероятных гипотез:\n",
    "1. Для генерации первого слова в последоватительности генерируем $h$ кандидатов, а не 1\n",
    "2. Генерируем $h \\times h$ кандидатов для второго слова и храним только $h$ наиболее вероятных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![nnlm](img/nlm2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 26\n"
     ]
    }
   ],
   "source": [
    "alphabet = list(set(chars))\n",
    "print('total chars:', len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb ngrams: 10701\n",
      "a a c h e n\n",
      "a c h e n o\n"
     ]
    }
   ],
   "source": [
    "maxlen = 5\n",
    "step = 1\n",
    "ngrams = []\n",
    "next_chars = []\n",
    "for name in names:\n",
    "    for i in range(0, len(name) - maxlen, step):\n",
    "        ngrams.append(' '.join([char for char in name[i: i + maxlen]]))\n",
    "        next_chars.append(name[i + maxlen])\n",
    "print('nb ngrams:', len(ngrams))\n",
    "print(ngrams[0],next_chars[0])\n",
    "print(ngrams[1],next_chars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 12, 11,  7], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(alphabet))\n",
    "tokenizer.fit_on_texts(ngrams)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(ngrams)\n",
    "X_train = pad_sequences(sequences, maxlen=maxlen)\n",
    "sequences = tokenizer.texts_to_sequences(next_chars)\n",
    "y_train = tokenizer.sequences_to_matrix(sequences)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "char_index = tokenizer.word_index\n",
    "index_char = {i: c for c, i in char_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(alphabet), 50, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'softmax'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation = 'softmax'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(alphabet), activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train,y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) #/ temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.choice(range(len(alphabet)), p = preds)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"katya\"\n",
      "katya\n",
      "katyab\n",
      "katyabo\n",
      "katyabok\n",
      "katyaboko\n",
      "katyabokoo\n",
      "katyabokool\n",
      "katyabokoolj\n",
      "katyabokooljy\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "generated = ''\n",
    "seed = 'katya'\n",
    "generated += seed\n",
    "print('----- Generating with seed: \"' + seed + '\"')\n",
    "print(generated)\n",
    "\n",
    "for i in range(8):\n",
    "    sequences = tokenizer.texts_to_sequences([' '.join([char for char in generated[-maxlen:]])])\n",
    "    X_pred = pad_sequences(sequences, maxlen=maxlen)\n",
    "    preds = model.predict(X_pred, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = index_char[next_index]\n",
    "    generated += next_char\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in 'abc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задание 3\n",
    "\n",
    "Измените код выше так, чтобы генерировались панграмы – имена динозавров, не содержащие повторяющихся букв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задание 4\n",
    "\n",
    "Измените функцию семлирования `sample`: добавьте параметр `t`, изпольузуемый для шкалирования вероятностей  `preds`: ```\n",
    "preds /= t\n",
    "``` \n",
    "\n",
    "Как использование этого параметра влияет на генерируемые имена?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Рекуррентные нейронные языковые модели\n",
    "\n",
    "RNN позволяют уйти от Марковских допущений и позволяют учитывать предысторию произвольной длины.\n",
    "\n",
    "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
    "\n",
    "$y_n = RNN(x_{1:n})$, $y_n \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "Для каждого префикса $x_{i:i}$ $y_i$ – выходной вектор.\n",
    "\n",
    "$y_i = RNN(x_{1:i})$\n",
    "\n",
    "$y_{1:n} = RNN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![rnn](img/rnn1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$R$ –  рекурсивная функция с двумя входами: $x_i$ и $s_{i-1}$ (вектор состояния)\n",
    "\n",
    "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
    "\n",
    "$y_i = O(s_i)$\n",
    "\n",
    "$s_i = R(s_{i-1}, x_i)$\n",
    "\n",
    "$s_i = R(s_{i-1}, x_i) = g(s_{i-1}* W^s + x_i W^x +b$\n",
    "\n",
    "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{d_{out}}$, $s_i \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "$W^x \\in \\mathbb{R}^{d_{in} \\times d_{in}}$, $W^s \\in \\mathbb{R}^{d_{out} \\times d_{out}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![rnn](img/rnn4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Обучение RNN: backpropogation through time (BPTT)\n",
    "\n",
    "![rnn](img/rnn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Сценарии использования RNN\n",
    "\n",
    "* Acceptor: только $y_n$, используемый для дальнейшего предсказания / классификации\n",
    "\n",
    "![rnn](img/rnn5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Encoder: только $y_n$\n",
    "\n",
    "![rnn](img/rnn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Transducer: выход $t_i$ для каждого входа $x_{1:i}$ – языковые модели,  sequence labelling\n",
    "\n",
    "![rnn](img/rnn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Двунаправленная рекуррентная нейронная сеть\n",
    "\n",
    "$x_{1:n}$ – входная последовательность\n",
    "\n",
    "$s_i^f$ –  \"прошлое / прямое состояние\" – основано на $x_{1:i}$\n",
    "\n",
    "$s_i^b$ –  \"будущее / обратное состояние\" – основано на $x_{n:i}$\n",
    "\n",
    "$y_i = [O(s_i^f), O(s_i^b)] = [y_i^f, y_i^b]$\n",
    "\n",
    "![rnn](img/birnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Управляемые архитектуры\n",
    "\n",
    "RNN трудно обучать: проблема исчезающего градиента. Уйти от нее помогают управляемые нейроны специального вида: LSTM и GRU.\n",
    "\n",
    "$s_i$ – память нейронной сети. Каждое использование $R$ считывает и видоизменяет всю память. \n",
    "\n",
    "Управляемый доступ к памяти: $g \\in {0,1}^n$:\n",
    "\n",
    "$s_{i+1} \\leftarrow g \\odot x + (1-g) \\odot s_{i}$\n",
    "\n",
    "Дифференцируемое управление:\n",
    "\n",
    "$g \\in \\mathbb{R}^n $:\n",
    "\n",
    "$s_{i+1} \\leftarrow \\sigma(g) \\odot x + (1-g) \\odot s_{i}$\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "X_names = ['bos ' + ' '.join(name) for name in names]\n",
    "Y_names = [' '.join(name) + ' eos' for name in names]\n",
    "maxlen = max([len(name) for name in names])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(alphabet)+2)\n",
    "tokenizer.fit_on_texts(X_names+Y_names)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_names)\n",
    "X_train = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(Y_names)\n",
    "Y_train = pad_sequences(sequences, padding='post')\n",
    "\n",
    "\n",
    "Y_train_cat  = [to_categorical(sent, num_classes=len(alphabet)+2) for sent in Y_train]\n",
    "Y_train =  np.asarray(Y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos a a c h e n o s a u r u s\n",
      "a a c h e n o s a u r u s eos\n",
      "(1536, 27)\n",
      "(1536, 27, 28)\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(X_names[0])\n",
    "print(Y_names[0])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(tokenizer.word_index['bos'])\n",
    "print(tokenizer.word_index['eos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "char_index = tokenizer.word_index\n",
    "index_char = {i: c for c, i in char_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(TimeDistributed(Dense(len(alphabet)+2, activation = 'softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 3.3283 - acc: 0.0134\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 800us/step - loss: 3.3120 - acc: 0.5274\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 893us/step - loss: 3.2945 - acc: 0.5229\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 745us/step - loss: 3.2749 - acc: 0.5221\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 690us/step - loss: 3.2520 - acc: 0.5210\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 673us/step - loss: 3.2243 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 676us/step - loss: 3.1892 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 717us/step - loss: 3.1432 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 778us/step - loss: 3.0802 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 811us/step - loss: 2.9901 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 914us/step - loss: 2.8565 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 758us/step - loss: 2.6554 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 678us/step - loss: 2.3757 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 675us/step - loss: 2.0831 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 675us/step - loss: 1.8717 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 694us/step - loss: 1.7634 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 679us/step - loss: 1.7452 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 831us/step - loss: 1.7866 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 709us/step - loss: 1.8470 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 669us/step - loss: 1.8952 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 678us/step - loss: 1.9183 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 817us/step - loss: 1.9157 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 699us/step - loss: 1.8925 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 684us/step - loss: 1.8555 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 685us/step - loss: 1.8115 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 673us/step - loss: 1.7667 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 675us/step - loss: 1.7264 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 673us/step - loss: 1.6945 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 697us/step - loss: 1.6734 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 680us/step - loss: 1.6632 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 672us/step - loss: 1.6625 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 680us/step - loss: 1.6680 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 672us/step - loss: 1.6758 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 726us/step - loss: 1.6820 - acc: 0.5205\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 770us/step - loss: 1.6840 - acc: 0.5210\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 833us/step - loss: 1.6808 - acc: 0.5210\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 942us/step - loss: 1.6726 - acc: 0.5210\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 815us/step - loss: 1.6609 - acc: 0.5210\n",
      "Epoch 1/1\n",
      "1536/1536 [==============================] - 1s 838us/step - loss: 1.6476 - acc: 0.5210\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c825da35b64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_train_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 200):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, Y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) #/ temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.choice(range(len(alphabet)+2), p = preds)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"bos\"\n",
      "bos \n",
      "bos u \n",
      "bos u m \n",
      "bos u m s \n",
      "bos u m s t \n",
      "bos u m s t u \n",
      "bos u m s t u u \n",
      "bos u m s t u u h \n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "seed = 'bos'\n",
    "generated += seed + ' '\n",
    "print('----- Generating with seed: \"' + seed + '\"')\n",
    "print(generated)\n",
    "\n",
    "\n",
    "for i in range(7): \n",
    "    sequences = tokenizer.texts_to_sequences([seed])\n",
    "    X_pred = pad_sequences(sequences, maxlen=maxlen, padding = 'post')\n",
    "\n",
    "    preds = model.predict(X_pred, verbose=0)[0]\n",
    "    samples = [sample(p) for p in preds]\n",
    "    next_index = samples[i]\n",
    "    while next_index == 0 or next_index == 10:\n",
    "        samples = [sample(p) for p in preds]\n",
    "        next_index = samples[i]\n",
    "    next_char = index_char[next_index]\n",
    "    generated += next_char + ' '\n",
    "    print(generated)\n",
    "    seed += next_char\n",
    "    if next_char == 'eos':\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задание 5\n",
    "\n",
    "Измените функцию семлирования `sample`: сейчас в ней используется простой выбор наиболее вероятного следующего элемента. Замените его на лучевой поиск [beam search].\n",
    "\n",
    "Как использование этой функции семплирования влияет на генерируемые имена?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0222358416238476e-10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# решение 1.1\n",
    "def name_prob(name):\n",
    "    p = unigram_prob(name[0])\n",
    "    for i in range(len(name)-1):\n",
    "        p *=  cprob[name[i]].prob(name[i+1])\n",
    "    return p\n",
    "\n",
    "name_prob(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tauronochi'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# решение 2\n",
    "def generate_name(cprob, first_char, num_chars):\n",
    "    name = ''\n",
    "    name += first_char\n",
    "    for i in range(num_chars):\n",
    "        char = cprob[first_char].generate()\n",
    "        name += char\n",
    "        first_char = char\n",
    "    return name\n",
    "\n",
    "generate_name(cprob, 't', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b31a15113dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# решение 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# решение 3\n",
    "for i in range(5):\n",
    "    sequences = tokenizer.texts_to_sequences([' '.join([char for char in generated[-maxlen:]])])\n",
    "    X_pred = pad_sequences(sequences, maxlen=maxlen)\n",
    "    preds = model.predict(X_pred, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = index_char[next_index]\n",
    "    if next_char not in generated:\n",
    "        generated += next_char\n",
    "        print(generated)\n",
    "    else:\n",
    "        preds[next_index] = 10e-5\n",
    "        next_index = sample(preds)\n",
    "        next_char = index_char[next_index]\n",
    "        generated += next_char\n",
    "        print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# решение 4\n",
    "def sample(preds, t=1.2):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / t\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.choice(range(len(alphabet)), p = preds)\n",
    "    return probas"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
