{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Машинное обучение для лингвистов\n",
    "\n",
    "## Екатерина Черняк\n",
    "\n",
    "echernyak@hse.ru\n",
    "\n",
    "чат в телеграме для вопросов: https://t.me/joinchat/EVGQlkTn6X4UQXxqbCKIlQ\n",
    "\n",
    "Wiki-страница:  http://wiki.cs.hse.ru/Машинное_обучение_для_лингвистов\n",
    "\n",
    "репозиторий: https://github.com/echernyak/ML-for-compling\n",
    "\n",
    "канал в телеграме для объявлений: https://t.me/ml_for_compling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# О курсе\n",
    "\n",
    "* Занятия по субботам, один раз в две недели, 11, 25 ноября, 9, 16 декабря, 12-10\n",
    "* 4 больших индивидуальных домашних задания (~раз в месяц)\n",
    "* 1 эссе по статье\n",
    "* По итогам всего курса должен быть сделан проект\n",
    "* Экзамен – презентация проекта\n",
    "* Оценка = 0.5 средняя оценка за дз и эссе + 0.5 оценка за проект\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# План\n",
    "\n",
    "### Кластеризация текстов\n",
    "1. Иерархическая кластеризация\n",
    "1. K-means\n",
    "1. DBScan\n",
    "1. Связь тематического моделирования и кластеризации \n",
    "1. *ДЗ: кластеризация новостей*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Классификация текстов \n",
    "1. Метод ближайшего соседа\n",
    "1. Метод наивного Байеса\n",
    "1. Метод максимальной энтропии \n",
    "1. Машины опорных векторов\n",
    "1. XGBoost\n",
    "1. *ДЗ: анализ новостей для предсказания рынка*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Классификация последовательностей\n",
    "1. Скрытые цепи Маркова\n",
    "1. Марковская модель максимальной энтропии\n",
    "1. Условные случайные поля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Нейронные сети\n",
    "1. Перцептрон\n",
    "1. Многослойный перцептрон\n",
    "1. Сверточные нейронные сети\n",
    "1. Word2vec, SENNA и FastText\n",
    "1.  *ДЗ: обучить SENNA на данных MorphRuEval*\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Языковые модели \n",
    "1. Счетные языковые модели\n",
    "1. Вероятностные языковые модели\n",
    "1. Рекуррентные нейронные сети, LSTM, GRU\n",
    "1. *ДЗ: соревнование FactRuEval*\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ### Современные модели\n",
    "1. Извлечение именованных сущностей (BiLSTM-CRF)\n",
    "1. Извлечение событий (slot filing)\n",
    "1. Машинный перевод (seq2seq)\n",
    "1. Генерация подписей (image captioning)\n",
    "1. Обучение с подкреплением (reinforcment learning)\n",
    "1. *Эссе по статье*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Учебники и ресурсы \n",
    "\n",
    "\n",
    "### Курсы: \n",
    "* Jurafsky & Martin [https://web.stanford.edu/~jurafsky/slp3/] \n",
    "* Курс Лауры Каллмайер по МО для АОТ [https://user.phil.hhu.de/~kallmeyer/MachineLearning/index.html]\n",
    "* Курс Нильса Раймерса по DL для АОТ [https://github.com/UKPLab/deeplearning4nlp-tutorial]\n",
    "* Курс в Оксфорде по DL для АОТ [https://github.com/oxford-cs-deepnlp-2017]\n",
    "* Курс в Стенфорде по DL для AOT [http://cs224d.stanford.edu ]\n",
    "* Материалы по обучению с подкреплением (Reinforcment Learning) [https://github.com/jiyfeng/rl4nlp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Учебники:\n",
    "* Manning, Christopher D., and Hinrich Schütze. Foundations of statistical natural language processing. Vol. 999. Cambridge: MIT press, 1999.\n",
    "* Martin, James H., and Daniel Jurafsky. \"Speech and language processing.\" International Edition 710 (2000): 25.\n",
    "* Cohen, Shay. \"Bayesian analysis in natural language processing.\" Synthesis Lectures on Human Language Technologies 9, no. 2 (2016): 1-274.\n",
    "* Goldberg, Yoav. \"Neural Network Methods for Natural Language Processing.\" Synthesis Lectures on Human Language Technologies 10, no. 1 (2017): 1-309.\n",
    "* Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
